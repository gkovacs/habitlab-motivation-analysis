{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook train_utils_extended.ipynb to python\r\n"
     ]
    }
   ],
   "source": [
    "# noexport\n",
    "\n",
    "!typech train_utils_extended.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from train_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, criterion, learning_rate, train_data):\n",
    "  total_loss = 0\n",
    "  confusion = [[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0]]\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for idx,item in enumerate(train_data):\n",
    "    category_tensor = item['category']\n",
    "    line_tensor = item['feature']\n",
    "    category = tensor_to_difficulty(item['category'])\n",
    "    category_i = get_difficulty_idx(category)\n",
    "    if line_tensor.size()[0] == 0:\n",
    "      continue\n",
    "    output,loss = train_transformer(model, criterion, category_tensor, line_tensor.permute(1,0,2), learning_rate)\n",
    "    total_loss += loss\n",
    "    guess = prediction_to_difficulty(output)\n",
    "    guess_i = get_difficulty_idx(guess)\n",
    "    if guess_i == category_i:\n",
    "      correct += 1\n",
    "    confusion[category_i][guess_i] += 1\n",
    "    total += 1\n",
    "  return {\n",
    "    'train_loss': total_loss,\n",
    "    'train_correct': correct,\n",
    "    'train_total': total,\n",
    "    'train_confusion': confusion,\n",
    "  }\n",
    "\n",
    "def train_model_for_parameters(parameter_info_list, num_epochs=3):\n",
    "  base_path_full = get_path_for_parameters(parameter_info_list)\n",
    "  base_path = 'tm_' + convert_string_to_hash(base_path_full)\n",
    "  if path.exists(base_path):\n",
    "    # todo check status file and resume training\n",
    "    return\n",
    "  else:\n",
    "    os.mkdir(base_path)\n",
    "  json.dump({'base_path': base_path}, open('current.json', 'w'))\n",
    "  status_info = {\n",
    "    'status': 'training',\n",
    "    'epoch': 0,\n",
    "    'base_path': base_path,\n",
    "    'base_path_full': base_path_full,\n",
    "    'dataset_name': dataset_name,\n",
    "    'start_time': str(arrow.get()),\n",
    "    'start_timestamp': arrow.get().timestamp,\n",
    "  }\n",
    "  print(base_path)\n",
    "  json.dump(parameter_info_list, open(path.join(base_path, 'parameters.json'), 'w'))\n",
    "  model = get_model_for_parameters(parameter_info_list)\n",
    "  learning_rate = get_parameter_value_for_info_list(parameter_info_list, 'learning_rate')\n",
    "  train_data,dev_data,test_data = get_data_for_parameters(parameter_info_list)\n",
    "  criterion = nn.NLLLoss()\n",
    "  for epoch in range(1, 1 + num_epochs):\n",
    "    status_info['epoch'] = epoch\n",
    "    json.dump(status_info, open(path.join(base_path, 'status.json'), 'w'))\n",
    "    print(status_info)\n",
    "    epoch_start_time = str(arrow.get())\n",
    "    epoch_start_timestamp = arrow.get().timestamp\n",
    "    model_path = path.join(base_path, 'model_' + str(epoch) + '.pt')\n",
    "    if path.exists(model_path):\n",
    "      continue\n",
    "    train_info = train_one_epoch(model, criterion, learning_rate, train_data)\n",
    "    save_model(model, criterion, epoch, train_info['train_loss'], model_path)\n",
    "    dev_info = evaluate_model_on_dataset(model, dev_data, 'dev_')\n",
    "    test_info = evaluate_model_on_dataset(model, test_data, 'test_')\n",
    "    for k,v in dev_info.items():\n",
    "      train_info[k] = v\n",
    "    for k,v in test_info.items():\n",
    "      train_info[k] = v\n",
    "    train_info['epoch_start_time'] = epoch_start_time\n",
    "    train_info['epoch_start_timestamp'] = epoch_start_timestamp\n",
    "    train_info['epoch_end_time'] = str(arrow.get())\n",
    "    train_info['epoch_end_timestamp'] = arrow.get().timestamp\n",
    "    training_start_timestamp = arrow.get().timestamp\n",
    "    info_path = path.join(base_path, 'info_' + str(epoch) + '.json')\n",
    "    json.dump(train_info, open(info_path, 'w'))\n",
    "  status_info['status'] = 'done'\n",
    "  status_info['end_time'] = str(arrow.get())\n",
    "  status_info['end_timestamp'] = arrow.get().timestamp\n",
    "  json.dump(status_info, open(path.join(base_path, 'status.json'), 'w'))\n",
    "  print(status_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "  while True:\n",
    "    parameters = sample_random_parameters(['learning_rate', 'window_embed_size', 'num_prior_entries'])\n",
    "    train_model_for_parameters(parameters)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tm_b94f084e6db75f16fb58d017c90f85345ce9573a\n",
      "{'name': 'model_name', 'type': 'model', 'values': ['selfattentionlstm'], 'value': 'selfattentionlstm'}\n",
      "{'name': 'criterion', 'type': 'model', 'values': ['NLLLoss'], 'value': 'NLLLoss'}\n",
      "{'name': 'learning_rate', 'type': 'model', 'values': [0.005, 0.05, 0.0005, 5e-05], 'value': 0.05}\n",
      "{'name': 'window_embed_size', 'type': 'model', 'values': [64, 128, 256, 512], 'value': 512}\n",
      "{'name': 'num_features', 'type': 'model', 'values': [277], 'value': 277}\n",
      "{'name': 'num_prior_entries', 'type': 'dataparam', 'values': [10, 20, 30, 40], 'value': 40}\n",
      "{'name': 'sample_every_n_visits', 'type': 'dataparam', 'values': [1], 'value': 1}\n",
      "{'name': 'sample_difficulty_every_n_visits', 'type': 'dataparam', 'values': [1], 'value': 1}\n",
      "{'name': 'disable_prior_visit_history', 'type': 'dataparam', 'values': [False, True], 'value': False}\n",
      "{'name': 'disable_difficulty_history', 'type': 'dataparam', 'values': [False, True], 'value': False}\n",
      "{'name': 'enable_current_difficulty', 'type': 'dataparam', 'values': [False, True], 'value': False}\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
