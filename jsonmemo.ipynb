{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noexport\n",
    "\n",
    "!typech jsonmemo.ipynb\n",
    "#import os\n",
    "#os.system('export_notebook jsonmemo.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  from typing import Dict, Any\n",
    "except ImportError:\n",
    "  pass\n",
    "\n",
    "import arrow\n",
    "import json\n",
    "import os, functools\n",
    "import msgpack\n",
    "import bson\n",
    "import torch\n",
    "import numpy\n",
    "\n",
    "def encode_custom(obj):\n",
    "  if isinstance(obj, arrow.Arrow):\n",
    "    return {'__arrow__': True, 'as_str': str(obj)}\n",
    "  if isinstance(obj, bson.objectid.ObjectId):\n",
    "    return {'__bsonid__': True, 'as_str': str(obj)}\n",
    "  if isinstance(obj, torch.Tensor):\n",
    "    torch_type = obj.type()\n",
    "    if torch_type == 'torch.FloatTensor':\n",
    "      numpy_obj = obj.numpy()\n",
    "      numpy_type = numpy_obj.dtype\n",
    "      if numpy_type == numpy.float32:\n",
    "        return {'__torch_tensor_float32__': True, 'as_str': json.dumps(numpy_obj.tolist())}\n",
    "  return obj\n",
    "\n",
    "def decode_custom(obj):\n",
    "  if '__arrow__' in obj:\n",
    "    return arrow.get(obj['as_str'])\n",
    "  if '__bsonid__' in obj:\n",
    "    return bson.objectid.ObjectId(obj['as_str'])\n",
    "  if '__torch_tensor_float32__' in obj:\n",
    "    return torch.tensor(numpy.array(json.loads(obj['as_str']), dtype='float32'), dtype=torch.float32)\n",
    "  return obj\n",
    "\n",
    "\n",
    "# # doesn't work with nested stuff (like dicts in argument lists)\n",
    "\n",
    "# cache_dirname = None\n",
    "\n",
    "# def set_cache_dirname(new_cache_dirname):\n",
    "#   global cache_dirname\n",
    "#   cache_dirname = new_cache_dirname\n",
    "\n",
    "# def get_cache_dirname():\n",
    "#   if cache_dirname == None:\n",
    "#     return 'cached_func_calls'\n",
    "#   return cache_dirname\n",
    "\n",
    "lowmem = False\n",
    "\n",
    "def set_lowmem(is_lowmem):\n",
    "  global lowmem\n",
    "  lowmem = is_lowmem\n",
    "\n",
    "funcname_to_is_lowmem = {} # type: Dict[str, bool]\n",
    "  \n",
    "def is_lowmem_funcname(funcname):\n",
    "  is_lowmem = funcname_to_is_lowmem.get(funcname, None)\n",
    "  if is_lowmem is not None:\n",
    "    return is_lowmem\n",
    "  return lowmem\n",
    "\n",
    "def set_lowmem_funcname(funcname, is_lowmem):\n",
    "  funcname_to_is_lowmem[funcname] = is_lowmem\n",
    "\n",
    "cached_jsonmemo_funcs = {} # type: Dict[str, Any]\n",
    "\n",
    "def create_jsonmemo_funcs(cache_dirname):\n",
    "  if cache_dirname in cached_jsonmemo_funcs:\n",
    "    return cached_jsonmemo_funcs[cache_dirname]\n",
    "  path_to_cache_mparr = {} # type: Dict[str, Any]\n",
    "  def mparrmemo(f):\n",
    "    if not os.path.isdir(cache_dirname):\n",
    "      os.mkdir(cache_dirname)\n",
    "      print('Created cache directory %s' % os.path.join(os.path.abspath(__file__), cache_dirname))\n",
    "\n",
    "    funcname = f.__name__\n",
    "    #cache_filename = f.__module__ + f.__name__ + '.json'\n",
    "    cache_filename = funcname + '.mparr'\n",
    "    cachepath = os.path.join(cache_dirname, cache_filename)\n",
    "    cache = None\n",
    "\n",
    "    @functools.wraps(f)\n",
    "    def wrapped():\n",
    "      nonlocal cache\n",
    "      if cache is not None:\n",
    "        #for x in cache:\n",
    "        #  yield cache\n",
    "        #return\n",
    "        return cache\n",
    "      cache = path_to_cache_mparr.get(funcname, None)\n",
    "      if cache is not None:\n",
    "        #for x in cache:\n",
    "        #  yield cache\n",
    "        #return\n",
    "        return cache\n",
    "      try:\n",
    "        cache = []\n",
    "        unpacker = msgpack.Unpacker(open(cachepath, 'rb'), raw=False, object_hook=decode_custom)\n",
    "        for unpacked in unpacker:\n",
    "          cache.append(unpacked)\n",
    "          #yield unpacked\n",
    "        #cache = json.load(open(cachepath), object_hook=decode_custom)\n",
    "        if not is_lowmem_funcname(funcname):\n",
    "          path_to_cache_mparr[funcname] = cache\n",
    "        return cache\n",
    "      except Exception as e:\n",
    "        print('exception in mparrmemo for file ' + cachepath)\n",
    "        print(e)\n",
    "        pass\n",
    "      print('performing computation ' + cachepath)\n",
    "      #cache = f()\n",
    "      cache = []\n",
    "      outfile = open(cachepath + '.tmp', 'wb')\n",
    "      for line in f():\n",
    "        cache.append(line)\n",
    "        outfile.write(msgpack.packb(line, default=encode_custom))\n",
    "      outfile.flush()\n",
    "      outfile.close()\n",
    "      os.replace(cachepath + '.tmp', cachepath)\n",
    "      print('done with computation ' + cachepath)\n",
    "      if not is_lowmem_funcname(funcname):\n",
    "        path_to_cache_mparr[funcname] = cache\n",
    "      #json.dump(cache, open(cachepath, 'w'), default=encode_custom)\n",
    "      #return cache\n",
    "      #for line in cache:\n",
    "      #  yield line\n",
    "      return cache\n",
    "    return wrapped\n",
    "\n",
    "  path_to_cache_msgpackmemo = {} # type: Dict[str, Any]\n",
    "  def msgpackmemo(f):\n",
    "    if not os.path.isdir(cache_dirname):\n",
    "      os.mkdir(cache_dirname)\n",
    "      print('Created cache directory %s' % os.path.join(os.path.abspath(__file__), cache_dirname))\n",
    "\n",
    "    funcname = f.__name__\n",
    "    #cache_filename = f.__module__ + f.__name__ + '.json'\n",
    "    cache_filename = funcname + '.msgpack'\n",
    "    cachepath = os.path.join(cache_dirname, cache_filename)\n",
    "    cache = None\n",
    "\n",
    "    @functools.wraps(f)\n",
    "    def wrapped():\n",
    "      nonlocal cache\n",
    "      if cache is not None:\n",
    "        return cache\n",
    "      cache = path_to_cache_msgpackmemo.get(funcname, None)\n",
    "      if cache is not None:\n",
    "        return cache\n",
    "      try:\n",
    "        cache = msgpack.load(open(cachepath, 'rb'), raw=False, object_hook=decode_custom)\n",
    "        if not is_lowmem_funcname(funcname):\n",
    "          path_to_cache_msgpackmemo[funcname] = cache\n",
    "        return cache\n",
    "      except Exception as e:\n",
    "        print('exception in msgpackmemo for file ' + cachepath)\n",
    "        print(e)\n",
    "        pass\n",
    "      cache = f()\n",
    "      if not is_lowmem_funcname(funcname):\n",
    "        path_to_cache_msgpackmemo[funcname] = cache\n",
    "      msgpack.dump(cache, open(cachepath, 'wb'), default=encode_custom)\n",
    "      return cache\n",
    "    return wrapped\n",
    "  \n",
    "  path_to_cache = {} # type: Dict[str, Any]\n",
    "  def jsonmemo(f):\n",
    "    if not os.path.isdir(cache_dirname):\n",
    "      os.mkdir(cache_dirname)\n",
    "      print('Created cache directory %s' % os.path.join(os.path.abspath(__file__), cache_dirname))\n",
    "\n",
    "    funcname = f.__name__\n",
    "    #cache_filename = f.__module__ + f.__name__ + '.json'\n",
    "    cache_filename = funcname + '.json'\n",
    "    cachepath = os.path.join(cache_dirname, cache_filename)\n",
    "    cache = None\n",
    "\n",
    "    @functools.wraps(f)\n",
    "    def wrapped():\n",
    "      nonlocal cache\n",
    "      if cache is not None:\n",
    "        return cache\n",
    "      cache = path_to_cache.get(funcname, None)\n",
    "      if cache is not None:\n",
    "        return cache\n",
    "      try:\n",
    "        cache = json.load(open(cachepath, 'rt'), object_hook=decode_custom)\n",
    "        if not is_lowmem_funcname(funcname):\n",
    "          path_to_cache[funcname] = cache\n",
    "        return cache\n",
    "      except Exception as e:\n",
    "        print('exception in jsonmemo for file ' + cachepath)\n",
    "        print(e)\n",
    "        pass\n",
    "      print('performing computation ' + cachepath)\n",
    "      cache = f()\n",
    "      print('done with computation ' + cachepath)\n",
    "      if not is_lowmem_funcname(funcname):\n",
    "        path_to_cache[funcname] = cache\n",
    "      json.dump(cache, open(cachepath, 'wt'), default=encode_custom)\n",
    "      return cache\n",
    "    return wrapped\n",
    "\n",
    "  path_to_cache_1arg = {} # type: Dict[str, Dict[Any, Any]]\n",
    "\n",
    "  def jsonmemo1arg(f):\n",
    "    if not os.path.isdir(cache_dirname):\n",
    "      os.mkdir(cache_dirname)\n",
    "      print('Created cache directory %s' % cache_dirname)\n",
    "    funcname = f.__name__\n",
    "    func_cache_dir = os.path.join(cache_dirname, funcname)\n",
    "    if not os.path.isdir(func_cache_dir):\n",
    "      os.mkdir(func_cache_dir)\n",
    "      print('Created cache directory %s' % func_cache_dir)\n",
    "\n",
    "    if funcname in path_to_cache_1arg:\n",
    "      cache = path_to_cache_1arg[funcname]\n",
    "    else:\n",
    "      cache = {}\n",
    "      path_to_cache_1arg[funcname] = cache\n",
    "\n",
    "    @functools.wraps(f)\n",
    "    def wrapped(arg1):\n",
    "      nonlocal cache\n",
    "      val = cache.get(arg1, None)\n",
    "      if val is not None:\n",
    "        return val\n",
    "      cachepath = os.path.join(func_cache_dir, str(arg1) + '.json')\n",
    "      try:\n",
    "        cacheitem = json.load(open(cachepath, 'rt'), object_hook=decode_custom)\n",
    "        if not is_lowmem_funcname(funcname):\n",
    "          path_to_cache_1arg[funcname][arg1] = cacheitem\n",
    "        return cacheitem\n",
    "      except Exception as e:\n",
    "        print('exception in jsonmemo1arg for file ' + cachepath)\n",
    "        print(e)\n",
    "        pass\n",
    "      print('performing computation ' + cachepath + ' for arg ' + str(arg1))\n",
    "      cacheitem = f(arg1)\n",
    "      print('done with computation ' + cachepath)\n",
    "      if not is_lowmem_funcname(funcname):\n",
    "        path_to_cache_1arg[funcname][arg1] = cacheitem\n",
    "      json.dump(cacheitem, open(cachepath, 'wt'), default=encode_custom)\n",
    "      return cacheitem\n",
    "    return wrapped\n",
    "\n",
    "  path_to_cache_msgpack1arg = {} # type: Dict[str, Dict[Any, Any]]\n",
    "  \n",
    "  def msgpackmemo1arg(f):\n",
    "    if not os.path.isdir(cache_dirname):\n",
    "      os.mkdir(cache_dirname)\n",
    "      print('Created cache directory %s' % cache_dirname)\n",
    "    funcname = f.__name__\n",
    "    func_cache_dir = os.path.join(cache_dirname, funcname)\n",
    "    if not os.path.isdir(func_cache_dir):\n",
    "      os.mkdir(func_cache_dir)\n",
    "      print('Created cache directory %s' % func_cache_dir)\n",
    "\n",
    "    if funcname in path_to_cache_msgpack1arg:\n",
    "      cache = path_to_cache_msgpack1arg[funcname]\n",
    "    else:\n",
    "      cache = {}\n",
    "      path_to_cache_msgpack1arg[funcname] = cache\n",
    "\n",
    "    @functools.wraps(f)\n",
    "    def wrapped(arg1):\n",
    "      nonlocal cache\n",
    "      val = cache.get(arg1, None)\n",
    "      if val is not None:\n",
    "        return val\n",
    "      cachepath = os.path.join(func_cache_dir, str(arg1) + '.msgpack')\n",
    "      try:\n",
    "        cacheitem = msgpack.load(open(cachepath, 'rb'), raw=False, object_hook=decode_custom)\n",
    "        if not is_lowmem_funcname(funcname):\n",
    "          path_to_cache_msgpack1arg[funcname][arg1] = cacheitem\n",
    "        return cacheitem\n",
    "      except Exception as e:\n",
    "        print('exception in msgpackmemo1arg for file ' + cachepath)\n",
    "        print(e)\n",
    "        pass\n",
    "      print('performing computation ' + cachepath + ' for arg ' + str(arg1))\n",
    "      cacheitem = f(arg1)\n",
    "      print('done with computation ' + cachepath)\n",
    "      if not is_lowmem_funcname(funcname):\n",
    "        path_to_cache_msgpack1arg[funcname][arg1] = cacheitem\n",
    "      msgpack.dump(cacheitem, open(cachepath, 'wb'), default=encode_custom)\n",
    "      return cacheitem\n",
    "    return wrapped\n",
    "  \n",
    "  path_to_cache_msgpack2arg = {} # type: Dict[str, Dict[Any, Dict[Any, Any]]]\n",
    "  \n",
    "  def msgpackmemo2arg(f):\n",
    "    if not os.path.isdir(cache_dirname):\n",
    "      os.mkdir(cache_dirname)\n",
    "      print('Created cache directory %s' % cache_dirname)\n",
    "    funcname = f.__name__\n",
    "    func_cache_dir = os.path.join(cache_dirname, funcname)\n",
    "    if not os.path.isdir(func_cache_dir):\n",
    "      os.mkdir(func_cache_dir)\n",
    "      print('Created cache directory %s' % func_cache_dir)\n",
    "\n",
    "    if funcname in path_to_cache_msgpack2arg:\n",
    "      cache = path_to_cache_msgpack2arg[funcname]\n",
    "    else:\n",
    "      cache = {}\n",
    "      path_to_cache_msgpack2arg[funcname] = cache\n",
    "\n",
    "    @functools.wraps(f)\n",
    "    def wrapped(arg1, arg2):\n",
    "      nonlocal cache\n",
    "      val = cache.get(arg1, None)\n",
    "      if val is not None:\n",
    "        return val\n",
    "      cachepath = os.path.join(func_cache_dir, str(arg1), str(arg2) + '.msgpack')\n",
    "      try:\n",
    "        cacheitem = msgpack.load(open(cachepath, 'rb'), raw=False, object_hook=decode_custom)\n",
    "        if not is_lowmem_funcname(funcname):\n",
    "          if arg1 not in path_to_cache_msgpack2arg[funcname]:\n",
    "            path_to_cache_msgpack2arg[funcname][arg1] = {}\n",
    "          path_to_cache_msgpack2arg[funcname][arg1][arg2] = cacheitem\n",
    "        return cacheitem\n",
    "      except Exception as e:\n",
    "        print('exception in msgpackmemo1arg for file ' + cachepath)\n",
    "        print(e)\n",
    "        pass\n",
    "      print('performing computation ' + cachepath + ' for arg ' + str(arg1))\n",
    "      cacheitem = f(arg1, arg2)\n",
    "      print('done with computation ' + cachepath)\n",
    "      if not is_lowmem_funcname(funcname):\n",
    "        if arg1 not in path_to_cache_msgpack2arg[funcname]:\n",
    "          path_to_cache_msgpack2arg[funcname][arg1] = {}\n",
    "        path_to_cache_msgpack2arg[funcname][arg1][arg2] = cacheitem\n",
    "      msgpack.dump(cacheitem, open(cachepath, 'wb'), default=encode_custom)\n",
    "      return cacheitem\n",
    "    return wrapped\n",
    "  \n",
    "  output = {\n",
    "    'jsonmemo': jsonmemo,\n",
    "    'jsonmemo1arg': jsonmemo1arg,\n",
    "    'mparrmemo': mparrmemo,\n",
    "    'msgpackmemo': msgpackmemo,\n",
    "    'msgpackmemo1arg': msgpackmemo1arg,\n",
    "    'msgpackmemo2arg': msgpackmemo2arg,\n",
    "  }\n",
    "  cached_jsonmemo_funcs[cache_dirname] = output\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from getsecret import getsecret\n",
    "# jsonmemo_funcs = create_jsonmemo_funcs(getsecret('DATA_DUMP'))\n",
    "# jsonmemo = jsonmemo_funcs['jsonmemo']\n",
    "# msgpackmemo = jsonmemo_funcs['msgpackmemo']\n",
    "\n",
    "\n",
    "# @msgpackmemo\n",
    "# def get_tensor_sample():\n",
    "#   a=torch.tensor([1], dtype=torch.float32)\n",
    "#   b=torch.tensor([2], dtype=torch.float32)\n",
    "#   c=torch.tensor([3], dtype=torch.float32)\n",
    "#   return [{'features': a}],[{'features': b}],[{'features': c}]\n",
    "\n",
    "# get_tensor_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache = json.load(open('/home/geza/motivation/2019_04_25/get_tensor_sample.json', 'rt'), object_hook=decode_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=json.loads(json.loads(open('/home/geza/motivation/2019_04_25/get_tensor_sample.json', 'rt').read())['as_str'])\n",
    "# b=numpy.array(a, dtype='float32')\n",
    "# c=torch.tensor(b, dtype=torch.float32)\n",
    "# #torch.tensor(numpy.array(json.load(open('/home/geza/motivation/2019_04_25/get_tensor_sample.json', 'rt')), dtype='float32'), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from getsecret import getsecret\n",
    "# jsonmemo_funcs = create_jsonmemo_funcs(getsecret('DATA_DUMP'))\n",
    "# jsonmemo1arg = jsonmemo_funcs['jsonmemo1arg']\n",
    "# jsonmemo = jsonmemo_funcs['jsonmemo']\n",
    "# mparrmemo = jsonmemo_funcs['mparrmemo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @mparrmemo\n",
    "# def get_all_features_data():\n",
    "#   print('get all features data should not be running')\n",
    "#   return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(get_all_features_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache = []\n",
    "# print('unpacker not yet started')\n",
    "# unpacker = msgpack.Unpacker(open('2019_04_08/get_all_features_data.mparr', 'rb'), raw=False, object_hook=decode_custom)\n",
    "# print('unpacker started')\n",
    "# print(type(unpacker))\n",
    "# for unpacked in unpacker:\n",
    "#   print(unpacked)\n",
    "#   break\n",
    "#   cache.append(unpacked)\n",
    "#   #yield unpacked\n",
    "# print('unpacker finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import msgpack\n",
    "\n",
    "# print('getting data_to_dump')\n",
    "# data_to_dump = msgpack.load(open('2019_04_08/get_all_features_data.msgpack', 'rb'))\n",
    "\n",
    "# print('starting to write outfile')\n",
    "# outfile = open('2019_04_08/get_all_features_data_v2.mparr', 'wb')\n",
    "# for line in data_to_dump:\n",
    "#   outfile.write(msgpack.packb(line))\n",
    "#   #outfile.write(msgpack.packb(line, use_bin_type=True)) #, default=encode_custom))\n",
    "# print('flushing')\n",
    "# outfile.flush()\n",
    "# outfile.close()\n",
    "# print('done')\n",
    "# #outfile.write()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacker = msgpack.Unpacker(open('2019_04_08/get_all_features_data.mparr', 'rb'), raw=False, object_hook=decode_custom) #, encoding='utf8')#, object_hook=decode_custom_msgpack)\n",
    "# for unpacked in unpacker:\n",
    "#   print(unpacked)\n",
    "#   #print(json.loads(json.dumps(unpacked)))\n",
    "#   break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
